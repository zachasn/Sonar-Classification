{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9D1seVBv0zyo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "  '''\n",
        "    Load data from the specified path.\n",
        "    path: str - file path\n",
        "    return: X, y - the features and labels\n",
        "  '''\n",
        "  data = pd.read_csv(path)\n",
        "  X = data.iloc[:, :-1].values\n",
        "  y = data.iloc[:, -1].values\n",
        "  y = LabelEncoder().fit_transform(y)\n",
        "  X = torch.tensor(X, dtype=torch.float32)\n",
        "  y = torch.tensor(y, dtype=torch.long)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "V2fXU3eY07j7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data(\"sonar.csv\")\n",
        "print(X.shape, y.shape)\n",
        "writer = SummaryWriter(log_dir='logs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPchvj-P08DK",
        "outputId": "c7574d9d-1366-44ec-ee72-e90bbaeed38e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([207, 60]) torch.Size([207])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split data using 70/20/10 split ratio\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=1)\n",
        "\n",
        "print(f\"x_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"x_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print(f\"x_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEzwKZdK08A1",
        "outputId": "64b6c863-bfe1-43b2-f6bb-22257a04e86f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train: torch.Size([144, 60]), y_train: torch.Size([144])\n",
            "x_val: torch.Size([21, 60]), y_val: torch.Size([21])\n",
            "x_test: torch.Size([42, 60]), y_test: torch.Size([42])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_nn(architecture: int, bias: bool=True):\n",
        "  '''\n",
        "    Build a neural network model with the specified architecture\n",
        "    architecture: int - the architecture of the model\n",
        "    bias: bool - whether to include bias or not\n",
        "    return: nn.Sequential - the model\n",
        "  '''\n",
        "\n",
        "  if architecture == 1: # 3 layers with ReLU activation function\n",
        "   return nn.Sequential(\n",
        "      nn.Linear(60, 30, bias=bias),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(30, 15, bias=bias),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(15, 2, bias=bias)\n",
        "   )\n",
        "  elif architecture == 2: # 5 layers with Tanh activation function\n",
        "    return nn.Sequential(\n",
        "      nn.Linear(60, 30, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(30, 15, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(15, 7, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(7, 3, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(3, 2, bias=bias)\n",
        "    )\n",
        "  elif architecture == 3: # 7 layers with Sigmoid activation function\n",
        "    return nn.Sequential(\n",
        "      nn.Linear(60, 50, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(50, 40, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(40, 30, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(30, 20, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(20, 10, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(10, 5, bias=bias),\n",
        "      nn.Sigmoid(),\n",
        "      nn.Dropout(),\n",
        "      nn.Linear(5, 2, bias=bias)\n",
        "    )\n",
        "  else: # 6 layers with Tanh activation function\n",
        "    return nn.Sequential(\n",
        "      nn.Linear(60, 50, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(50, 40, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(40, 20, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(20, 15, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(15, 10, bias=bias),\n",
        "      nn.Tanh(),\n",
        "      nn.Linear(10, 2, bias=bias)\n",
        "    )"
      ],
      "metadata": {
        "id": "PYZDLyFI07-e"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, data_loader, loss_fn, optimizer):\n",
        "  '''\n",
        "    code from lecture 22\n",
        "    Train the model using the training data.\n",
        "    model: nn.Module - the model to train\n",
        "    data_loader: DataLoader - the data loader for training data\n",
        "    loss_fn: nn.CrossEntropyLoss - the loss function\n",
        "    optimizer: optim - the optimizer\n",
        "    return: float - the loss of the model\n",
        "  '''\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(data_loader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "  return epoch_loss\n",
        "\n",
        "def test_loop(model, data_loader, loss_fn):\n",
        "  '''\n",
        "    code from lecture 22\n",
        "    Test the model using the validation data.\n",
        "    model: nn.Module - the model to test\n",
        "    data_loader: DataLoader - the data loader for validation data\n",
        "    loss_fn: nn.CrossEntropyLoss - the loss function\n",
        "    return: float - the loss of the model\n",
        "  '''\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_loader:\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "  return test_loss\n",
        "\n",
        "\n",
        "def calculate_accuracy(model, data_loader):\n",
        "  '''\n",
        "    Calculate the accuracy of the model.\n",
        "    model: nn.Module - the model to test\n",
        "    data_loader: DataLoader - the data loader for the data\n",
        "    return: float - the accuracy score of the model\n",
        "  '''\n",
        "  model.eval()\n",
        "  true_y = []\n",
        "  pred_y = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_loader:\n",
        "      pred = model(X)\n",
        "      _, predicted = torch.max(pred, 1)\n",
        "      true_y.extend(y.tolist())\n",
        "      pred_y.extend(predicted.tolist())\n",
        "  return accuracy_score(true_y, pred_y)"
      ],
      "metadata": {
        "id": "4P2yabNM078K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parameter_tuning(architecture: int, optimizers: list, learning_rates: list, epochs: int, batch_size: int, X_train, y_train, X_val, y_val):\n",
        "  '''\n",
        "    Finds the best parameters for a given model.\n",
        "    architecture: int - the architecture of the model\n",
        "    optimizers: list - the list of optimizers to use\n",
        "    learning_rates: list - the list of learning rates to use\n",
        "    epochs: int - the number of epochs to run\n",
        "    batch_size: int - the batch size\n",
        "    X_train: torch.Tensor - the training features\n",
        "    y_train: torch.Tensor - the training labels\n",
        "    X_val: torch.Tensor - the validation features\n",
        "    y_val: torch.Tensor - the validation labels\n",
        "    return: dict - dictionary that contains the best parameters\n",
        "  '''\n",
        "  best_loss = float('inf')\n",
        "  best_params = None\n",
        "\n",
        "  for opt in optimizers:\n",
        "    for lr in learning_rates:\n",
        "      for bs in batch_size:\n",
        "        #print(f\"Running with optimizer: {opt}, learning rate: {lr}, batch size: {bs}\")\n",
        "        model = build_nn(architecture)\n",
        "        train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=bs, shuffle=True)\n",
        "        val_loader = DataLoader(list(zip(X_val, y_val)), batch_size=bs, shuffle=False)\n",
        "\n",
        "        if opt == \"SGD\":\n",
        "          optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "        elif opt == \"Adam\":\n",
        "          optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "        elif opt == \"RMSprop\":\n",
        "          optimizer = optim.RMSprop(model.parameters(), lr=lr)\n",
        "        else:\n",
        "          optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
        "\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "          train_loss = train_loop(model, train_loader, loss_fn, optimizer)\n",
        "          val_loss = test_loop(model, val_loader, loss_fn)\n",
        "\n",
        "          train_accuracy = calculate_accuracy(model, train_loader)\n",
        "          val_accuracy = calculate_accuracy(model, val_loader)\n",
        "\n",
        "          writer.add_scalar(f\"Loss/train_{opt}_{lr}_{bs}\", train_loss, epoch)\n",
        "          writer.add_scalar(f\"Loss/test_{opt}_{lr}_{bs}\", val_loss, epoch)\n",
        "          writer.add_scalar(f\"train_accuracy_{opt}_{lr}_{bs}\", train_accuracy, epoch)\n",
        "          writer.add_scalar(f\"test_accuracy_{opt}_{lr}_{bs}\", val_accuracy, epoch)\n",
        "\n",
        "          if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_params = {\"lr\": lr, \"epoch\": epoch, \"bs\": bs, \"optimizer\": opt, \"accuracy\": val_accuracy}\n",
        "  return best_params"
      ],
      "metadata": {
        "id": "gPcmQUKu1QJI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [16, 32, 64]\n",
        "epochs = 1000\n",
        "optimizers = [\"SGD\", \"Adam\", \"RMSprop\", \"Adagrad\"]"
      ],
      "metadata": {
        "id": "wbtM8dlW1P_f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters for each model\n",
        "model_1_params = parameter_tuning(1, optimizers, learning_rates, epochs, batch_sizes, X_train, y_train, X_val, y_val)\n",
        "model_2_params = parameter_tuning(2, optimizers, learning_rates, epochs, batch_sizes, X_train, y_train, X_val, y_val)\n",
        "model_3_params = parameter_tuning(3, optimizers, learning_rates, epochs, batch_sizes, X_train, y_train, X_val, y_val)\n",
        "model_4_params = parameter_tuning(4, optimizers, learning_rates, epochs, batch_sizes, X_train, y_train, X_val, y_val)"
      ],
      "metadata": {
        "id": "Dgefe3Ut070n"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model 1 parameters: {model_1_params}\")\n",
        "print(f\"Model 2 parameters: {model_2_params}\")\n",
        "print(f\"Model 3 parameters: {model_3_params}\")\n",
        "print(f\"Model 4 parameters: {model_4_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50JLg4ox1WCd",
        "outputId": "e9b09258-0ad5-492f-e59b-85e8794a8f79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 parameters: {'lr': 0.01, 'epoch': 231, 'bs': 64, 'optimizer': 'RMSprop', 'accuracy': 0.8095238095238095}\n",
            "Model 2 parameters: {'lr': 0.001, 'epoch': 764, 'bs': 64, 'optimizer': 'RMSprop', 'accuracy': 0.8571428571428571}\n",
            "Model 3 parameters: {'lr': 0.01, 'epoch': 298, 'bs': 64, 'optimizer': 'RMSprop', 'accuracy': 0.8571428571428571}\n",
            "Model 4 parameters: {'lr': 0.1, 'epoch': 645, 'bs': 64, 'optimizer': 'SGD', 'accuracy': 0.8571428571428571}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(architecture: int, best_params: dict, X_train, y_train, X_test, y_test):\n",
        "  '''\n",
        "    Evaluate the model with the best parameters using the test data\n",
        "    architecture: int - the architecture of the model\n",
        "    best_params: dict - the best parameters for the model\n",
        "    X_train: torch.Tensor - the training features\n",
        "    y_train: torch.Tensor - the training labels\n",
        "    X_test: torch.Tensor - the test features\n",
        "    y_test: torch.Tensor - the test labels\n",
        "    return: nn.Module - the trained model\n",
        "  '''\n",
        "  model = build_nn(architecture)\n",
        "  train_loader = DataLoader(list(zip(X_train, y_train)), batch_size=best_params[\"bs\"], shuffle=True)\n",
        "  test_loader = DataLoader(list(zip(X_test, y_test)), batch_size=best_params[\"bs\"], shuffle=False)\n",
        "\n",
        "  if best_params[\"optimizer\"] == \"SGD\":\n",
        "    optimizer = optim.SGD(model.parameters(), lr=best_params[\"lr\"])\n",
        "  elif best_params[\"optimizer\"] == \"Adam\":\n",
        "    optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
        "  elif best_params[\"optimizer\"] == \"RMSprop\":\n",
        "    optimizer = optim.RMSprop(model.parameters(), lr=best_params[\"lr\"])\n",
        "  else:\n",
        "    optimizer = optim.Adagrad(model.parameters(), lr=best_params[\"lr\"])\n",
        "\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(best_params[\"epoch\"]):\n",
        "    train_loss = train_loop(model, train_loader, loss_fn, optimizer)\n",
        "    writer.add_scalar(f\"Loss/train_{architecture}\", train_loss, epoch)\n",
        "  test_loss = test_loop(model, test_loader, loss_fn)\n",
        "  test_accuracy = calculate_accuracy(model, test_loader)\n",
        "  writer.add_scalar(f\"Loss/test_{architecture}\", test_loss, 0)\n",
        "  writer.add_scalar(f\"test_accuracy_{architecture}\", test_accuracy, 0)\n",
        "  print(f\"Test loss for model {architecture}: {test_loss}, Test accuracy for model {architecture}: {test_accuracy}\")\n",
        "\n",
        "  return model, test_accuracy"
      ],
      "metadata": {
        "id": "w05RdQVI1bQS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1, model_1_accuracy = test_model(1, model_1_params, X_train, y_train, X_test, y_test)\n",
        "model_2, model_2_accuracy = test_model(2, model_2_params, X_train, y_train, X_test, y_test)\n",
        "model_3, model_3_accuracy = test_model(3, model_3_params, X_train, y_train, X_test, y_test)\n",
        "model_4, model_4_accuracy = test_model(4, model_4_params, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA0tjipI1dw_",
        "outputId": "965f1094-1540-46cb-fc8c-40a8d44d0d79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss for model 1: 0.5587701201438904, Test accuracy for model 1: 0.8095238095238095\n",
            "Test loss for model 2: 0.6173585653305054, Test accuracy for model 2: 0.8095238095238095\n",
            "Test loss for model 3: 0.6978033781051636, Test accuracy for model 3: 0.47619047619047616\n",
            "Test loss for model 4: 0.3148244023323059, Test accuracy for model 4: 0.8809523809523809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = [model_1_accuracy, model_2_accuracy, model_3_accuracy, model_4_accuracy]\n",
        "best_model = np.argmax(accuracies) + 1"
      ],
      "metadata": {
        "id": "G2fy-HPh1fY7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The best model is model {best_model} with an accuracy of {accuracies[best_model - 1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwE3ipSn1iGj",
        "outputId": "bef55033-96eb-46de-f806-af325830aa79"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    }
  ]
}